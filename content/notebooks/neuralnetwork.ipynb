{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Neural Network From Scratch\"\n",
    "date: 2019-07-31T07:48:41+07:00\n",
    "categories:\n",
    "- Machine Learning\n",
    "tags:\n",
    "- Macine Learning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "Artificial neural network is no magic. The main purpose of neural network (and any classical machine learning algorithm) is to find out `magic numbers` in order to find out the best `classifier` or `regressor`.\n",
    "\n",
    "Suppose we have the following data:\n",
    "\n",
    "```\n",
    "age height weight\n",
    "50  170    75\n",
    "40  180    ?\n",
    "```\n",
    "\n",
    "Now, we want to know the weight of someone whose age is `40`, and height is `180`.\n",
    "\n",
    "This is a regression problem. Mathematically you can formulate the problem as follow:\n",
    "\n",
    "$$weight = w1.age + w2.height + w3$$\n",
    "\n",
    "Now our goal is to find out 3 magic numbers, `w1`, `w2`, and `w3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple approach (Non-neural-network)\n",
    "\n",
    "You might be tempted to solve the equation using pure `algebra`. Since we have single data with three variables (aka: the magic numbers), I think we can't solve the equation with pure algebra.\n",
    "\n",
    "So, let's solve the using brute-force experiments!!!\n",
    "\n",
    "## Finding the regressor\n",
    "\n",
    "First of all, we have to define our `loss function` (how far we are from the target). In our case, the loss function is as follow:\n",
    "\n",
    "$$error = |actual\\_weight - predicted\\_weight|$$\n",
    "$$error = |actual\\_weight - (w1.age + w2.height + w3)|$$\n",
    "\n",
    "Let's implement the loss function in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(actual_weight, w1, age, w2, height, w3):\n",
    "    error = abs(actual_weight - (w1*age + w2*height + w3))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to assign `1`-`100` to `w1`, `w2`, and `w3` in order to get the best numbers for each of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 0.0 w1: -101 w2: 30 w3: 25\n",
      "error: 0.0 w1: -100 w2: 30 w3: -25\n",
      "error: 0.0 w1: -99 w2: 29 w3: 95\n",
      "error: 0.0 w1: -99 w2: 30 w3: -75\n",
      "error: 0.0 w1: -98 w2: 29 w3: 45\n",
      "error: 0.0 w1: -97 w2: 29 w3: -5\n",
      "error: 0.0 w1: -96 w2: 29 w3: -55\n",
      "error: 0.0 w1: -95 w2: 28 w3: 65\n",
      "error: 0.0 w1: -94 w2: 28 w3: 15\n",
      "error: 0.0 w1: -93 w2: 28 w3: -35\n",
      "error: 0.0 w1: -92 w2: 27 w3: 85\n",
      "error: 0.0 w1: -92 w2: 28 w3: -85\n",
      "error: 0.0 w1: -91 w2: 27 w3: 35\n",
      "error: 0.0 w1: -90 w2: 27 w3: -15\n",
      "error: 0.0 w1: -89 w2: 27 w3: -65\n",
      "error: 0.0 w1: -88 w2: 26 w3: 55\n",
      "error: 0.0 w1: -87 w2: 26 w3: 5\n",
      "error: 0.0 w1: -86 w2: 26 w3: -45\n",
      "error: 0.0 w1: -85 w2: 25 w3: 75\n",
      "error: 0.0 w1: -85 w2: 26 w3: -95\n",
      "error: 0.0 w1: -84 w2: 25 w3: 25\n",
      "error: 0.0 w1: -83 w2: 25 w3: -25\n",
      "error: 0.0 w1: -82 w2: 24 w3: 95\n",
      "error: 0.0 w1: -82 w2: 25 w3: -75\n",
      "error: 0.0 w1: -81 w2: 24 w3: 45\n",
      "error: 0.0 w1: -80 w2: 24 w3: -5\n",
      "error: 0.0 w1: -79 w2: 24 w3: -55\n",
      "error: 0.0 w1: -78 w2: 23 w3: 65\n",
      "error: 0.0 w1: -77 w2: 23 w3: 15\n",
      "error: 0.0 w1: -76 w2: 23 w3: -35\n",
      "error: 0.0 w1: -75 w2: 22 w3: 85\n",
      "error: 0.0 w1: -75 w2: 23 w3: -85\n",
      "error: 0.0 w1: -74 w2: 22 w3: 35\n",
      "error: 0.0 w1: -73 w2: 22 w3: -15\n",
      "error: 0.0 w1: -72 w2: 22 w3: -65\n",
      "error: 0.0 w1: -71 w2: 21 w3: 55\n",
      "error: 0.0 w1: -70 w2: 21 w3: 5\n",
      "error: 0.0 w1: -69 w2: 21 w3: -45\n",
      "error: 0.0 w1: -68 w2: 20 w3: 75\n",
      "error: 0.0 w1: -68 w2: 21 w3: -95\n",
      "error: 0.0 w1: -67 w2: 20 w3: 25\n",
      "error: 0.0 w1: -66 w2: 20 w3: -25\n",
      "error: 0.0 w1: -65 w2: 19 w3: 95\n",
      "error: 0.0 w1: -65 w2: 20 w3: -75\n",
      "error: 0.0 w1: -64 w2: 19 w3: 45\n",
      "error: 0.0 w1: -63 w2: 19 w3: -5\n",
      "error: 0.0 w1: -62 w2: 19 w3: -55\n",
      "error: 0.0 w1: -61 w2: 18 w3: 65\n",
      "error: 0.0 w1: -60 w2: 18 w3: 15\n",
      "error: 0.0 w1: -59 w2: 18 w3: -35\n",
      "error: 0.0 w1: -58 w2: 17 w3: 85\n",
      "error: 0.0 w1: -58 w2: 18 w3: -85\n",
      "error: 0.0 w1: -57 w2: 17 w3: 35\n",
      "error: 0.0 w1: -56 w2: 17 w3: -15\n",
      "error: 0.0 w1: -55 w2: 17 w3: -65\n",
      "error: 0.0 w1: -54 w2: 16 w3: 55\n",
      "error: 0.0 w1: -53 w2: 16 w3: 5\n",
      "error: 0.0 w1: -52 w2: 16 w3: -45\n",
      "error: 0.0 w1: -51 w2: 15 w3: 75\n",
      "error: 0.0 w1: -51 w2: 16 w3: -95\n",
      "error: 0.0 w1: -50 w2: 15 w3: 25\n",
      "error: 0.0 w1: -49 w2: 15 w3: -25\n",
      "error: 0.0 w1: -48 w2: 14 w3: 95\n",
      "error: 0.0 w1: -48 w2: 15 w3: -75\n",
      "error: 0.0 w1: -47 w2: 14 w3: 45\n",
      "error: 0.0 w1: -46 w2: 14 w3: -5\n",
      "error: 0.0 w1: -45 w2: 14 w3: -55\n",
      "error: 0.0 w1: -44 w2: 13 w3: 65\n",
      "error: 0.0 w1: -43 w2: 13 w3: 15\n",
      "error: 0.0 w1: -42 w2: 13 w3: -35\n",
      "error: 0.0 w1: -41 w2: 12 w3: 85\n",
      "error: 0.0 w1: -41 w2: 13 w3: -85\n",
      "error: 0.0 w1: -40 w2: 12 w3: 35\n",
      "error: 0.0 w1: -39 w2: 12 w3: -15\n",
      "error: 0.0 w1: -38 w2: 12 w3: -65\n",
      "error: 0.0 w1: -37 w2: 11 w3: 55\n",
      "error: 0.0 w1: -36 w2: 11 w3: 5\n",
      "error: 0.0 w1: -35 w2: 11 w3: -45\n",
      "error: 0.0 w1: -34 w2: 10 w3: 75\n",
      "error: 0.0 w1: -34 w2: 11 w3: -95\n",
      "error: 0.0 w1: -33 w2: 10 w3: 25\n",
      "error: 0.0 w1: -32 w2: 10 w3: -25\n",
      "error: 0.0 w1: -31 w2: 9 w3: 95\n",
      "error: 0.0 w1: -31 w2: 10 w3: -75\n",
      "error: 0.0 w1: -30 w2: 9 w3: 45\n",
      "error: 0.0 w1: -29 w2: 9 w3: -5\n",
      "error: 0.0 w1: -28 w2: 9 w3: -55\n",
      "error: 0.0 w1: -27 w2: 8 w3: 65\n",
      "error: 0.0 w1: -26 w2: 8 w3: 15\n",
      "error: 0.0 w1: -25 w2: 8 w3: -35\n",
      "error: 0.0 w1: -24 w2: 7 w3: 85\n",
      "error: 0.0 w1: -24 w2: 8 w3: -85\n",
      "error: 0.0 w1: -23 w2: 7 w3: 35\n",
      "error: 0.0 w1: -22 w2: 7 w3: -15\n",
      "error: 0.0 w1: -21 w2: 7 w3: -65\n",
      "error: 0.0 w1: -20 w2: 6 w3: 55\n",
      "error: 0.0 w1: -19 w2: 6 w3: 5\n",
      "error: 0.0 w1: -18 w2: 6 w3: -45\n",
      "error: 0.0 w1: -17 w2: 5 w3: 75\n",
      "error: 0.0 w1: -17 w2: 6 w3: -95\n",
      "error: 0.0 w1: -16 w2: 5 w3: 25\n",
      "error: 0.0 w1: -15 w2: 5 w3: -25\n",
      "error: 0.0 w1: -14 w2: 4 w3: 95\n",
      "error: 0.0 w1: -14 w2: 5 w3: -75\n",
      "error: 0.0 w1: -13 w2: 4 w3: 45\n",
      "error: 0.0 w1: -12 w2: 4 w3: -5\n",
      "error: 0.0 w1: -11 w2: 4 w3: -55\n",
      "error: 0.0 w1: -10 w2: 3 w3: 65\n",
      "error: 0.0 w1: -9 w2: 3 w3: 15\n",
      "error: 0.0 w1: -8 w2: 3 w3: -35\n",
      "error: 0.0 w1: -7 w2: 2 w3: 85\n",
      "error: 0.0 w1: -7 w2: 3 w3: -85\n",
      "error: 0.0 w1: -6 w2: 2 w3: 35\n",
      "error: 0.0 w1: -5 w2: 2 w3: -15\n",
      "error: 0.0 w1: -4 w2: 2 w3: -65\n",
      "error: 0.0 w1: -3 w2: 1 w3: 55\n",
      "error: 0.0 w1: -2 w2: 1 w3: 5\n",
      "error: 0.0 w1: -1 w2: 1 w3: -45\n",
      "error: 0.0 w1: 0 w2: 0 w3: 75\n",
      "error: 0.0 w1: 0 w2: 1 w3: -95\n",
      "error: 0.0 w1: 1 w2: 0 w3: 25\n",
      "error: 0.0 w1: 2 w2: 0 w3: -25\n",
      "error: 0.0 w1: 3 w2: -1 w3: 95\n",
      "error: 0.0 w1: 3 w2: 0 w3: -75\n",
      "error: 0.0 w1: 4 w2: -1 w3: 45\n",
      "error: 0.0 w1: 5 w2: -1 w3: -5\n",
      "error: 0.0 w1: 6 w2: -1 w3: -55\n",
      "error: 0.0 w1: 7 w2: -2 w3: 65\n",
      "error: 0.0 w1: 8 w2: -2 w3: 15\n",
      "error: 0.0 w1: 9 w2: -2 w3: -35\n",
      "error: 0.0 w1: 10 w2: -3 w3: 85\n",
      "error: 0.0 w1: 10 w2: -2 w3: -85\n",
      "error: 0.0 w1: 11 w2: -3 w3: 35\n",
      "error: 0.0 w1: 12 w2: -3 w3: -15\n",
      "error: 0.0 w1: 13 w2: -3 w3: -65\n",
      "error: 0.0 w1: 14 w2: -4 w3: 55\n",
      "error: 0.0 w1: 15 w2: -4 w3: 5\n",
      "error: 0.0 w1: 16 w2: -4 w3: -45\n",
      "error: 0.0 w1: 17 w2: -5 w3: 75\n",
      "error: 0.0 w1: 17 w2: -4 w3: -95\n",
      "error: 0.0 w1: 18 w2: -5 w3: 25\n",
      "error: 0.0 w1: 19 w2: -5 w3: -25\n",
      "error: 0.0 w1: 20 w2: -6 w3: 95\n",
      "error: 0.0 w1: 20 w2: -5 w3: -75\n",
      "error: 0.0 w1: 21 w2: -6 w3: 45\n",
      "error: 0.0 w1: 22 w2: -6 w3: -5\n",
      "error: 0.0 w1: 23 w2: -6 w3: -55\n",
      "error: 0.0 w1: 24 w2: -7 w3: 65\n",
      "error: 0.0 w1: 25 w2: -7 w3: 15\n",
      "error: 0.0 w1: 26 w2: -7 w3: -35\n",
      "error: 0.0 w1: 27 w2: -8 w3: 85\n",
      "error: 0.0 w1: 27 w2: -7 w3: -85\n",
      "error: 0.0 w1: 28 w2: -8 w3: 35\n",
      "error: 0.0 w1: 29 w2: -8 w3: -15\n",
      "error: 0.0 w1: 30 w2: -8 w3: -65\n",
      "error: 0.0 w1: 31 w2: -9 w3: 55\n",
      "error: 0.0 w1: 32 w2: -9 w3: 5\n",
      "error: 0.0 w1: 33 w2: -9 w3: -45\n",
      "error: 0.0 w1: 34 w2: -10 w3: 75\n",
      "error: 0.0 w1: 34 w2: -9 w3: -95\n",
      "error: 0.0 w1: 35 w2: -10 w3: 25\n",
      "error: 0.0 w1: 36 w2: -10 w3: -25\n",
      "error: 0.0 w1: 37 w2: -11 w3: 95\n",
      "error: 0.0 w1: 37 w2: -10 w3: -75\n",
      "error: 0.0 w1: 38 w2: -11 w3: 45\n",
      "error: 0.0 w1: 39 w2: -11 w3: -5\n",
      "error: 0.0 w1: 40 w2: -11 w3: -55\n",
      "error: 0.0 w1: 41 w2: -12 w3: 65\n",
      "error: 0.0 w1: 42 w2: -12 w3: 15\n",
      "error: 0.0 w1: 43 w2: -12 w3: -35\n",
      "error: 0.0 w1: 44 w2: -13 w3: 85\n",
      "error: 0.0 w1: 44 w2: -12 w3: -85\n",
      "error: 0.0 w1: 45 w2: -13 w3: 35\n",
      "error: 0.0 w1: 46 w2: -13 w3: -15\n",
      "error: 0.0 w1: 47 w2: -13 w3: -65\n",
      "error: 0.0 w1: 48 w2: -14 w3: 55\n",
      "error: 0.0 w1: 49 w2: -14 w3: 5\n",
      "error: 0.0 w1: 50 w2: -14 w3: -45\n",
      "error: 0.0 w1: 51 w2: -15 w3: 75\n",
      "error: 0.0 w1: 51 w2: -14 w3: -95\n",
      "error: 0.0 w1: 52 w2: -15 w3: 25\n",
      "error: 0.0 w1: 53 w2: -15 w3: -25\n",
      "error: 0.0 w1: 54 w2: -16 w3: 95\n",
      "error: 0.0 w1: 54 w2: -15 w3: -75\n",
      "error: 0.0 w1: 55 w2: -16 w3: 45\n",
      "error: 0.0 w1: 56 w2: -16 w3: -5\n",
      "error: 0.0 w1: 57 w2: -16 w3: -55\n",
      "error: 0.0 w1: 58 w2: -17 w3: 65\n",
      "error: 0.0 w1: 59 w2: -17 w3: 15\n",
      "error: 0.0 w1: 60 w2: -17 w3: -35\n",
      "error: 0.0 w1: 61 w2: -18 w3: 85\n",
      "error: 0.0 w1: 61 w2: -17 w3: -85\n",
      "error: 0.0 w1: 62 w2: -18 w3: 35\n",
      "error: 0.0 w1: 63 w2: -18 w3: -15\n",
      "error: 0.0 w1: 64 w2: -18 w3: -65\n",
      "error: 0.0 w1: 65 w2: -19 w3: 55\n",
      "error: 0.0 w1: 66 w2: -19 w3: 5\n",
      "error: 0.0 w1: 67 w2: -19 w3: -45\n",
      "error: 0.0 w1: 68 w2: -20 w3: 75\n",
      "error: 0.0 w1: 68 w2: -19 w3: -95\n",
      "error: 0.0 w1: 69 w2: -20 w3: 25\n",
      "error: 0.0 w1: 70 w2: -20 w3: -25\n",
      "error: 0.0 w1: 71 w2: -21 w3: 95\n",
      "error: 0.0 w1: 71 w2: -20 w3: -75\n",
      "error: 0.0 w1: 72 w2: -21 w3: 45\n",
      "error: 0.0 w1: 73 w2: -21 w3: -5\n",
      "error: 0.0 w1: 74 w2: -21 w3: -55\n",
      "error: 0.0 w1: 75 w2: -22 w3: 65\n",
      "error: 0.0 w1: 76 w2: -22 w3: 15\n",
      "error: 0.0 w1: 77 w2: -22 w3: -35\n",
      "error: 0.0 w1: 78 w2: -23 w3: 85\n",
      "error: 0.0 w1: 78 w2: -22 w3: -85\n",
      "error: 0.0 w1: 79 w2: -23 w3: 35\n",
      "error: 0.0 w1: 80 w2: -23 w3: -15\n",
      "error: 0.0 w1: 81 w2: -23 w3: -65\n",
      "error: 0.0 w1: 82 w2: -24 w3: 55\n",
      "error: 0.0 w1: 83 w2: -24 w3: 5\n",
      "error: 0.0 w1: 84 w2: -24 w3: -45\n",
      "error: 0.0 w1: 85 w2: -25 w3: 75\n",
      "error: 0.0 w1: 85 w2: -24 w3: -95\n",
      "error: 0.0 w1: 86 w2: -25 w3: 25\n",
      "error: 0.0 w1: 87 w2: -25 w3: -25\n",
      "error: 0.0 w1: 88 w2: -26 w3: 95\n",
      "error: 0.0 w1: 88 w2: -25 w3: -75\n",
      "error: 0.0 w1: 89 w2: -26 w3: 45\n",
      "error: 0.0 w1: 90 w2: -26 w3: -5\n",
      "error: 0.0 w1: 91 w2: -26 w3: -55\n",
      "error: 0.0 w1: 92 w2: -27 w3: 65\n",
      "error: 0.0 w1: 93 w2: -27 w3: 15\n",
      "error: 0.0 w1: 94 w2: -27 w3: -35\n",
      "error: 0.0 w1: 95 w2: -28 w3: 85\n",
      "error: 0.0 w1: 95 w2: -27 w3: -85\n",
      "error: 0.0 w1: 96 w2: -28 w3: 35\n",
      "error: 0.0 w1: 97 w2: -28 w3: -15\n",
      "error: 0.0 w1: 98 w2: -28 w3: -65\n",
      "error: 0.0 w1: 99 w2: -29 w3: 55\n",
      "error: 0.0 w1: 100 w2: -29 w3: 5\n"
     ]
    }
   ],
   "source": [
    "age = 50.0\n",
    "height = 170.0\n",
    "actual_weight = 75.0\n",
    "best_error = 0 # error threshold, we are only interested for error that is less or equal to 0\n",
    "\n",
    "for w1 in range(-101, 101):\n",
    "    for w2 in range(-100, 101):\n",
    "        for w3 in range(-100, 101):\n",
    "            error = loss_function(actual_weight, w1, age, w2, height, w3)\n",
    "            if error <= best_error:\n",
    "                best_error = error\n",
    "                print(\"error:\", error, \"w1:\", w1, \"w2:\", w2, \"w3:\", w3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, we have several predictors!!! \n",
    "\n",
    "Let's take the first one: `w1=-100`, `w2=30`, and `w3=-25`\n",
    "\n",
    "For `age=50`, `height=170`, we get\n",
    "\n",
    "$$prediction\\_weight = -100 . 50 + 30 . 170 - 25 . 1$$\n",
    "$$prediction\\_weight = -5000 + 5100 - 25$$\n",
    "$$prediction\\_weight = 75$$\n",
    "\n",
    "The `prediction_weight` is equal to `actual_weight`!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the regressor\n",
    "\n",
    "Finally, for `age=40` and `weight=180`, we get this:\n",
    "\n",
    "$$prediction\\_weight = -100.40 + 30.180 - 25.1$$\n",
    "$$prediction\\_weight = -4000 + 5400 - 25$$\n",
    "$$prediction\\_weight = 1375$$\n",
    "\n",
    "Well, not so make sense, probably we need to use another available predictor.\n",
    "\n",
    "__Note:__ If your problem can be perfectly solved with pure-algebra/brute-force. Just use them for your own good. Neural network or any other machine learning algorithm, should only be used if the solution is not obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What just happened?\n",
    "\n",
    "We have just jump into a problem named `overfitting`. Overfitting is a problem where our predictor/regressor is correct for the training data, but incorrect for the testing data.\n",
    "\n",
    "Another problems with our approach are:\n",
    "\n",
    "* we naively believe that w1, w2, and w3 are integer\n",
    "* we naively believe that the predictor is a straight linear line. Probably we need some logarithm, power, and other eccentric operations in order to get the correct predictor/classifier\n",
    "\n",
    "Neural networks can definitely solve our two last problems. Overfitting is still a common problem in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network approach\n",
    "\n",
    "As already stated, neural network is no magic.\n",
    "\n",
    "In our previous approach, the regressor is formulated as follow: \n",
    "\n",
    "$$weight = w1.age + w2.height + w3$$\n",
    "\n",
    "Suppose we have a function `f` to process the result, the regressor should looks like this:\n",
    "\n",
    "$$weight = f(w1.age + w2.height + w3)$$\n",
    "\n",
    "This is what a single neuron in neural network do !!!\n",
    "\n",
    "![]()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network implementation using Tensorflow\n",
    "\n",
    "TensorFlow is an open-source software library for dataflow programming across a range of tasks. It is a symbolic math library, and is also used for machine learning applications such as neural networks.\n",
    "\n",
    "Unlike `sklearn.neural_network`, tensorflow give us more freedom to set up our neural-network.\n",
    "\n",
    "First of all, let's try to import tensorflow and keras (which is now also part of tensorflow)\n",
    "\n",
    "## Importing Tensorflow and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the dataset\n",
    "\n",
    "We will try to perform classification task on mnist's dataset (http://yann.lecun.com/exdb/mnist/). The dataset contains of `70000` gray-scale images. Each image has `28 x 28` dimension and belong to one (and only one) of the following 10 classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's download `fashion_mnist` dataset from `keras.datasets` and split them into `train` and `test` set. By default, the dataset contains of `60000` training set and `10000` test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the data a little bit\n",
    "\n",
    "Here is a bit information about our `train_labels`. It is a one-dimension array with 60000 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's explore our `train_images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure, let's see our first image and label in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  5\n",
      "which is:  five\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "label = train_labels[index]\n",
    "image = train_images[index]\n",
    "\n",
    "print(\"label: \", label) # this is the first train_labels\n",
    "print(\"which is: \", class_names[label]) # use our pre-defined class_names to get textual representation of the label\n",
    "plt.figure()\n",
    "plt.imshow(image) # if you just want to see the matrix representation of the image, use `image` instead\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the neural network model\n",
    "\n",
    "Finally, let's build our neural network.\n",
    "\n",
    "First of all, we define 3 layers here:\n",
    "\n",
    "* flatten layer with input_shape = 28x28: This one will transform our 2 dimensional matrix into 1 dimensional matrix (or a vector). The output of this layer will be an array with 784 elements\n",
    "* dense layer containing 1024 neuron with sigmoid activation: This one will create a layer containing 128 neuron. Each of them is connected to the output of our previous layer (an array containing 784 elements). Each neuron activation is depending on `sigmoid` function (https://en.wikipedia.org/wiki/Sigmoid_function)\n",
    "* dense layer containing 10 neuron with softmax activation: Finally, since we have 10 classes, it is natural to have 10 neuron in our output layer. Each neuron should show us how probable is an image belong to a particular class. Finally, we will use softmax to return the prediction result (https://en.wikipedia.org/wiki/Softmax_function)\n",
    "\n",
    "After defining the layers, we need to define our optimizer, loss function, and metrics:\n",
    "\n",
    "* optimizer: How to optimize. We use adam optimization (https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)\n",
    "* loss function: How to calculate error\n",
    "* metrics: How to measure the quality of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(1024, activation=tf.nn.sigmoid),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 133us/sample - loss: 0.3687 - accuracy: 0.8954\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 0.2767 - accuracy: 0.9184\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 8s 131us/sample - loss: 0.2467 - accuracy: 0.9273\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 0.2285 - accuracy: 0.9304\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 0.2158 - accuracy: 0.9337\n",
      "10000/10000 [==============================] - 1s 71us/sample - loss: 0.1969 - accuracy: 0.9367\n",
      "Test accuracy: 0.9367\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target label:  7 seven\n",
      "prediction label:  7 seven\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(test_images)\n",
    "np.argmax(predictions[0])\n",
    "\n",
    "index = 0\n",
    "prediction_label = np.argmax(predictions[0])\n",
    "target_label = test_labels[index]\n",
    "image = test_images[index]\n",
    "\n",
    "print(\"target label: \", target_label, class_names[target_label])\n",
    "print(\"prediction label: \", prediction_label, class_names[prediction_label])\n",
    "plt.figure()\n",
    "plt.imshow(image) # if you just want to see the matrix representation of the image, use `image` instead\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further discussion\n",
    "\n",
    "For classical machine learning (as this one), data preprocessing is quite important. Please look at this: https://github.com/shayan09/MNIST-Handwriting-Recognition-using-Keras/blob/master/Basic%20Keras%20NN.ipynb for comparison."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
